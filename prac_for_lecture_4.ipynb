{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4292afe7",
   "metadata": {},
   "source": [
    "## команды запуска среды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cdeda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dfc3371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"lsml-app-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a6bbc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e995de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "##spark = ## старт вашей спарк сессии на машине\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735bc1a9",
   "metadata": {},
   "source": [
    "## материал семинара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "153ec3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window ## пр-во методов под оконные ф-ии, но мы в семинаре их не рассмортим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db62bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## учебный пример фрема данных на семинар"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7141637b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://rc1a-dataproc-m-rudh7kbav7bkht94.mdb.yandexcloud.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>lsml-app-1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff1714f3a00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark ## смотрим на описание запущенной мной спарк сессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da67267a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[continent: string, country: string, name: string, population: bigint]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## здесь создаем тестовый пример набора данных, с которым будем работать в рамках семинара\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "test_data = [\n",
    "{\"name\":\"Moscow\", \"country\":\"Russia\", \"continent\": \"Europe\", \"population\": 100_000_000},\n",
    "{ \"name\":\"Madrid\", \"country\":\"Spain\" },\n",
    "{ \"name\":\"Paris\", \"country\":\"France\", \"continent\": \"Europe\", \"population\" : 205_000_000},\n",
    "{ \"name\":\"Berlin\", \"country\":\"Germany\", \"continent\": \"Europe\", \"population\": 140_000_008},\n",
    "{ \"name\":\"Barselona\", \"country\":\"Spain\", \"continent\": \"Europe\" },\n",
    "{ \"name\":\"Cairo\", \"country\":\"Egypt\", \"continent\": \"Africa\", \"population\": 45_000_001 },\n",
    "{ \"name\":\"Cairo\", \"country\":\"Egypt\", \"continent\": \"Africa\", \"population\": 45_000_001 },\n",
    "]\n",
    "\n",
    "## создаем rdd\n",
    "rdd = sc.parallelize(test_data)\n",
    "\n",
    "## создаем DataFrame абстракцию поверх rdd\n",
    "df = spark.read.json(rdd).localCheckpoint()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f2c3c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\r\n"
     ]
    }
   ],
   "source": [
    "!pwd ## команда для получения пути до вашей home папки и места запуска ноутбука"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d1358cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continent,country,name,population\r\n",
      "Europe,Russia,Moscow,100000000.0\r\n",
      ",Spain,Madrid,\r\n",
      "Europe,France,Paris,205000000.0\r\n",
      "Europe,Germany,Berlin,140000008.0\r\n",
      "Europe,Spain,Barselona,\r\n",
      "Africa,Egypt,Cairo,45000001.0\r\n",
      "Africa,Egypt,Cairo,45000001.0\r\n"
     ]
    }
   ],
   "source": [
    "cat population.csv | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef93bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -put population.csv /user/ubuntu/population.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3659eb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "drwxr-xr-x   - ubuntu hadoop          0 2026-02-16 12:18 /user/ubuntu/.sparkStaging\r\n",
      "-rw-r--r--   1 ubuntu hadoop        232 2026-02-16 12:21 /user/ubuntu/population.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls -h /user/ubuntu/ ## здесь смотрим на путь до моей юзер папки на HDFS!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd93fa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[continent: string, country: string, name: string, population: double]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# чтение файла по пути папки под юзером на HDFS\n",
    "\n",
    "read_df = (\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"csv\")\n",
    "    .options(\n",
    "        header=True,\n",
    "        inferSchema=True,\n",
    "        sep=\",\"\n",
    "    )\n",
    "    .load(\"/user/ubuntu/population.csv\")\n",
    "\n",
    ")\n",
    "\n",
    "read_df # <-  сформированный DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9c8b40c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------\n",
      " continent  | Europe       \n",
      " country    | Russia       \n",
      " name       | Moscow       \n",
      " population | 1.0E8        \n",
      "-RECORD 1------------------\n",
      " continent  | null         \n",
      " country    | Spain        \n",
      " name       | Madrid       \n",
      " population | null         \n",
      "-RECORD 2------------------\n",
      " continent  | Europe       \n",
      " country    | France       \n",
      " name       | Paris        \n",
      " population | 2.05E8       \n",
      "-RECORD 3------------------\n",
      " continent  | Europe       \n",
      " country    | Germany      \n",
      " name       | Berlin       \n",
      " population | 1.40000008E8 \n",
      "-RECORD 4------------------\n",
      " continent  | Europe       \n",
      " country    | Spain        \n",
      " name       | Barselona    \n",
      " population | null         \n",
      "-RECORD 5------------------\n",
      " continent  | Africa       \n",
      " country    | Egypt        \n",
      " name       | Cairo        \n",
      " population | 4.5000001E7  \n",
      "-RECORD 6------------------\n",
      " continent  | Africa       \n",
      " country    | Egypt        \n",
      " name       | Cairo        \n",
      " population | 4.5000001E7  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_df.show(vertical=True) # вызываем action, смотрим данные в вертикальном разрезе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa272038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#запись файла по пути до папки юзера на HDFS\n",
    "\n",
    "(\n",
    "    read_df\n",
    "    .write\n",
    "    .format(\"parquet\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(\"/user/ubuntu/population_parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad6668f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2026-02-16 12:21 /user/ubuntu/population_parquet/_SUCCESS\r\n",
      "-rw-r--r--   1 ubuntu hadoop      1.3 K 2026-02-16 12:21 /user/ubuntu/population_parquet/part-00000-2b67caa5-f14f-4309-919a-0a53a2ff3494-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls -h /user/ubuntu/population_parquet/ # тут наблюдаем за тем как файл успешно записался"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb59f419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAR1\u0015\u0004\u0015(\u0015,L\u0015\u0004\u0015\u0004\u0000\u0000\u0014L\u0006\u0000\u0000\u0000Europe\u0006\u0000\u0000\u0000Africa\u0015\u0000\u0015\u0012\u0015\u0016,\u0015\u000e\u0015\u0004\u0015\u0006\u0015\b\u001c",
      "6\u0002(\u0006Europe\u0018\u0006Africa\u0000\u0000\u0000\t \u0002\u0000\u0000\u0000\u0003}\u0001\u00030\u0015\u0004\u0015b\u0015dL\u0015\r\n",
      "\u0015\u0004\u0000\u00001H\u0006\u0000\u0000\u0000Russia\u0005\u0000\u0000\u0000Spain\u0001\u0013dFrance\u0007\u0000\u0000\u0000Germany\u0005\u0000\u0000\u0000Egypt\u0015\u0000\u0015\u0016\u0015\u001a,\u0015\u000e\u0015\u0004\u0015\u0006\u0015\b\u001c",
      "6\u0000(\u0005Spain\u0018\u0005Egypt\u0000\u0000\u0000\u000b",
      "(\u0002\u0000\u0000\u0000\u0003\u0003\u0003�\u0016\u0012\u0015\u0004\u0015z\u0015xL\u0015\f",
      "\u0015\u0004\u0000\u0000=$\u0006\u0000\u0000\u0000Moscow\u0005\r\n",
      "4adrid\u0005\u0000\u0000\u0000Paris\u0001\u0013lBerlin\t\u0000\u0000\u0000Barselona\u0005\u0000\u0000\u0000Cairo\u0015\u0000\u0015\u0016\u0015\u001a,\u0015\u000e\u0015\u0004\u0015\u0006\u0015\b\u001c",
      "6\u0000(\u0005Paris\u0018\tBarselona\u0000\u0000\u0000\u000b",
      "(\u0002\u0000\u0000\u0000\u0003\u0003\u0003��\u0016\u0015\u0004\u0015@\u0015BL\u0015\b\u0015\u0004\u0000\u0000 8\u0000\u0000\u0000\u0000�חA\u0000\u0000\u0000�\u001ap�\u0001\b0\u0010v��A\u0000\u0000\u0000\b*u�A\u0015\u0000\u0015\u0014\u0015\u0018,\u0015\u000e\u0015\u0004\u0015\u0006\u0015\b\u001c",
      "\u0018\b\u0000\u0000\u0000�\u001ap�A\u0018\b\u0000\u0000\u0000\b*u�A\u0016\u0004(\b\u0000\u0000\u0000�\u001ap�A\u0018\b\u0000\u0000\u0000\b*u�A\u0000\u0000\u0000\r\n",
      "$\u0002\u0000\u0000\u0000\u0003m\u0002\u0003�\u0003\u0015\u0002\u0019\\H\f",
      "spark_schema\u0015\b\u0000\u0015\f",
      "%\u0002\u0018\tcontinent%\u0000\u0000\u0015\f",
      "%\u0002\u0018\u0007country%\u0000\u0000\u0015\f",
      "%\u0002\u0018\u0004name%\u0000\u0000\u0015\r\n",
      "%\u0002\u0018\r\n",
      "population\u0000\u0016\u000e\u0019\u001c",
      "\u0019L&\b\u001c",
      "\u0015\f",
      "\u00195\u0006\b\u0004\u0019\u0018\tcontinent\u0015\u0002\u0016\u000e\u0016�\u0001\u0016�\u0001&\b<6\u0002(\u0006Europe\u0018\u0006Africa\u0000\u0019,\u0015\u0004\u0015\u0004\u0015\u0002\u0000\u0015\u0000\u0015\u0004\u0015\u0002\u0000\u0000\u0000&�\u0001\u001c",
      "\u0015\f",
      "\u00195\u0006\b\u0004\u0019\u0018\u0007country\u0015\u0002\u0016\u000e\u0016�\u0001\u0016�\u0001&�\u0001<6\u0000(\u0005Spain\u0018\u0005Egypt\u0000\u0019,\u0015\u0004\u0015\u0004\u0015\u0002\u0000\u0015\u0000\u0015\u0004\u0015\u0002\u0000\u0000\u0000&�\u0003\u001c",
      "\u0015\f",
      "\u00195\u0006\b\u0004\u0019\u0018\u0004name\u0015\u0002\u0016\u000e\u0016�\u0001\u0016�\u0001&�\u0003<6\u0000(\u0005Paris\u0018\tBarselona\u0000\u0019,\u0015\u0004\u0015\u0004\u0015\u0002\u0000\u0015\u0000\u0015\u0004\u0015\u0002\u0000\u0000\u0000&�\u0005\u001c",
      "\u0015\r\n",
      "\u00195\u0006\b\u0004\u0019\u0018\r\n",
      "population\u0015\u0002\u0016\u000e\u0016�\u0001\u0016�\u0001&�\u0005<\u0018\b\u0000\u0000\u0000�\u001ap�A\u0018\b\u0000\u0000\u0000\b*u�A\u0016\u0004(\b\u0000\u0000\u0000�\u001ap�A\u0018\b\u0000\u0000\u0000\b*u�A\u0000\u0019,\u0015\u0004\u0015\u0004\u0015\u0002\u0000\u0015\u0000\u0015\u0004\u0015\u0002\u0000\u0000\u0000\u0016�\u0006\u0016\u000e\u0000\u0019,\u0018\u0018org.apache.spark.version\u0018\u00053.0.3\u0000\u0018)org.apache.spark.sql.parquet.row.metadata\u0018�\u0002{\"type\":\"struct\",\"fields\":[{\"name\":\"continent\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"country\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"population\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}}]}\u0000\u0018Jparquet-mr version 1.10.1 (build a89df8f9932b6ef6633d06069e50c9b7970bebd1)\u0019L\u001c",
      "\u0000\u0000\u001c",
      "\u0000\u0000\u001c",
      "\u0000\u0000\u001c",
      "\u0000\u0000\u0000i\u0003\u0000\u0000PAR1"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/ubuntu/population_parquet/* # тут попытались вывести файл на чтение в консоль\n",
    "# но формат паркет хранит данные бинарно, так что просто так их не прочитать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14afc5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continent</th>\n",
       "      <th>country</th>\n",
       "      <th>name</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>100000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europe</td>\n",
       "      <td>France</td>\n",
       "      <td>Paris</td>\n",
       "      <td>205000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>140000008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barselona</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>45000001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>45000001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  continent  country       name   population\n",
       "0    Europe   Russia     Moscow  100000000.0\n",
       "1       NaN    Spain     Madrid          NaN\n",
       "2    Europe   France      Paris  205000000.0\n",
       "3    Europe  Germany     Berlin  140000008.0\n",
       "4    Europe    Spain  Barselona          NaN\n",
       "5    Africa    Egypt      Cairo   45000001.0\n",
       "6    Africa    Egypt      Cairo   45000001.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Создание DataFrame от локального файла, он лежит рядом с ноутбуком, не на HDFS!!!\n",
    "import pandas as pd\n",
    "\n",
    "pdf = pd.read_csv(\"population.csv\")\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4719bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pdf = (\n",
    "    spark.createDataFrame(pdf,\n",
    "                         ) ## создание DataFrame от локально pandas объекта\n",
    ")\n",
    "\n",
    "test_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "71860d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continent</th>\n",
       "      <th>country</th>\n",
       "      <th>name</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>100000000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europe</td>\n",
       "      <td>France</td>\n",
       "      <td>Paris</td>\n",
       "      <td>205000000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>140000008.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barselona</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>45000001.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>45000001.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  continent  country       name    population\n",
       "0    Europe   Russia     Moscow 100000000.000\n",
       "1      None    Spain     Madrid           NaN\n",
       "2    Europe   France      Paris 205000000.000\n",
       "3    Europe  Germany     Berlin 140000008.000\n",
       "4    Europe    Spain  Barselona           NaN\n",
       "5    Africa    Egypt      Cairo  45000001.000\n",
       "6    Africa    Egypt      Cairo  45000001.000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pdf.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2e0d1c",
   "metadata": {},
   "source": [
    "Смотрим на методы взаимодействия с DataFrame:\n",
    "- select\n",
    "- filter\n",
    "- dropDuplicates\n",
    "- na.fill\n",
    "- replace\n",
    "- orderBy\n",
    "\n",
    "Триггерные действия:\n",
    "- show\n",
    "- save\n",
    "- saveAsTable - просто рассказать\n",
    "\n",
    "документация со всем, что может пригодиться:\n",
    "- методы к DataFrame - https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html\n",
    "- методы из sql.functions - https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html\n",
    "\n",
    "- Посмотрим .explain() и на сами планы\n",
    "- alias и когда он нужен\n",
    "- join и как выглядят их планы вычислений\n",
    "\n",
    "Будем переодически смотреть на UI и как там все это выглядит\n",
    "\n",
    "Полезная ссылка - https://habr.com/ru/articles/901078/ - тут написано про Catalyst и как он оптимизирует ваши запросы к данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d52af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Важно добавить, в sql.functions методах для указания колонок, над которыми данные хотите применить методы\n",
    "## указывать колонки через перечисление string переменных, либо через метод F.col() - к которому также можно применять свои методы\n",
    "## Второй подход более предпочтительный, так как к объектам колонок F.col() можно применить дополнительные методы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4950327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [*]\n",
      "+- 'Filter ('a.name = Moscow)\n",
      "   +- 'Join Inner, ('a.name = 'b.name)\n",
      "      :- 'SubqueryAlias a\n",
      "      :  +- 'UnresolvedRelation [test_test]\n",
      "      +- 'SubqueryAlias b\n",
      "         +- 'UnresolvedRelation [test_test]\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "continent: string, country: string, name: string, population: bigint, continent: string, country: string, name: string, population: bigint\n",
      "Project [continent#6, country#7, name#8, population#9L, continent#148, country#149, name#150, population#151L]\n",
      "+- Filter (name#8 = Moscow)\n",
      "   +- Join Inner, (name#8 = name#150)\n",
      "      :- SubqueryAlias a\n",
      "      :  +- SubqueryAlias test_test\n",
      "      :     +- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "      +- SubqueryAlias b\n",
      "         +- SubqueryAlias test_test\n",
      "            +- LogicalRDD [continent#148, country#149, name#150, population#151L], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Join Inner, (name#8 = name#150)\n",
      ":- Filter (isnotnull(name#8) AND (name#8 = Moscow))\n",
      ":  +- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "+- Filter ((name#150 = Moscow) AND isnotnull(name#150))\n",
      "   +- LogicalRDD [continent#148, country#149, name#150, population#151L], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(5) SortMergeJoin [name#8], [name#150], Inner\n",
      ":- *(2) Sort [name#8 ASC NULLS FIRST], false, 0\n",
      ":  +- Exchange hashpartitioning(name#8, 200), true, [id=#147]\n",
      ":     +- *(1) Filter (isnotnull(name#8) AND (name#8 = Moscow))\n",
      ":        +- *(1) Scan ExistingRDD[continent#6,country#7,name#8,population#9L]\n",
      "+- *(4) Sort [name#150 ASC NULLS FIRST], false, 0\n",
      "   +- ReusedExchange [continent#148, country#149, name#150, population#151L], Exchange hashpartitioning(name#8, 200), true, [id=#147]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Посмотреть как выглядит реализация какой-то задачи на SQL\n",
    "\n",
    "df.createOrReplaceTempView(\"test_test\") ## создание метки view для обращения к ней через \"FROM test_test\" \n",
    "\n",
    "\n",
    "## Далее всем знакомый вам SQL код\n",
    "spark.sql(\"\"\"\n",
    "    select *\n",
    "    \n",
    "    from test_test as a join test_test as b on a.name = b.name\n",
    "    \n",
    "    where a.name = 'Moscow'\n",
    "\n",
    "\"\"\").explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c88b4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-------+----------+---------+-------+----------+\n",
      "|  name|continent|country|population|continent|country|population|\n",
      "+------+---------+-------+----------+---------+-------+----------+\n",
      "|Moscow|   Europe| Russia| 100000000|   Europe| Russia| 100000000|\n",
      "+------+---------+-------+----------+---------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Реализация запроса выше через DataFrame методы\n",
    "\n",
    "(\n",
    "    df\n",
    "    .select(\"*\")\n",
    "    .join(\n",
    "        df,\n",
    "        on=[\"name\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .filter(F.col(\"name\") == \"Moscow\")\n",
    "    .show()\n",
    ")\n",
    "\n",
    "## реализовали .select(\"*\") - всех колонок, но так делать не стоит!!! явно указывайте список нужных колонок\n",
    "## .join() - джоин первого датафрейма ко второму по нужной колонке и с условием inner\n",
    "## добавление фильтра по колонке name с опр значениями в ней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1fa714c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------+\n",
      "|     name|continent|country|\n",
      "+---------+---------+-------+\n",
      "|   Moscow|   Europe| Russia|\n",
      "|   Madrid|     null|  Spain|\n",
      "|    Paris|   Europe| France|\n",
      "|   Berlin|   Europe|Germany|\n",
      "|Barselona|   Europe|  Spain|\n",
      "|    Cairo|   Africa|  Egypt|\n",
      "|    Cairo|   Africa|  Egypt|\n",
      "+---------+---------+-------+\n",
      "\n",
      "== Parsed Logical Plan ==\n",
      "'Project [unresolvedalias('name, None), unresolvedalias('continent, None), unresolvedalias('country, None)]\n",
      "+- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "name: string, continent: string, country: string\n",
      "Project [name#8, continent#6, country#7]\n",
      "+- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [name#8, continent#6, country#7]\n",
      "+- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [name#8, continent#6, country#7]\n",
      "+- *(1) Scan ExistingRDD[continent#6,country#7,name#8,population#9L]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## разбираем отдельно методы и их планы запросов:\n",
    "    \n",
    "(\n",
    "    df\n",
    "    .select(\"name\", \"continent\", \"country\") ## метод выбора нужных колонок из дата фрейма\n",
    "    .show()\n",
    ")\n",
    "\n",
    "(\n",
    "    df\n",
    "    .select(\"name\", \"continent\", \"country\")\n",
    "    .explain(True)\n",
    ")\n",
    "\n",
    "## по плану запроса видно, что Physical Plan (физический движок с вызовом конкретных методов)\n",
    "## сначала делает скан  коллекции а после вызывает метод Project для выделения нужных колонок из данных\n",
    "## ПЛАНЫ ЗАПРОСОВ ЧИТАЮТСЯ СНИЗУ ВВЕРХ\n",
    "\n",
    "## отличия каждого из планов более подробно разобраны на лекции, в блоке про их чтение и определение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f924da7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+------+----------+\n",
      "|continent|country|  name|population|\n",
      "+---------+-------+------+----------+\n",
      "|   Europe| Russia|Moscow| 100000000|\n",
      "+---------+-------+------+----------+\n",
      "\n",
      "== Parsed Logical Plan ==\n",
      "'Filter ('name = Moscow)\n",
      "+- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "continent: string, country: string, name: string, population: bigint\n",
      "Filter (name#8 = Moscow)\n",
      "+- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Filter (isnotnull(name#8) AND (name#8 = Moscow))\n",
      "+- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(name#8) AND (name#8 = Moscow))\n",
      "+- *(1) Scan ExistingRDD[continent#6,country#7,name#8,population#9L]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .filter(F.col(\"name\") == \"Moscow\") ## условие фильтрации данных по значению из колонки, аналог WHERE в SQL\n",
    "    .show()\n",
    ")\n",
    "\n",
    "(\n",
    "    df\n",
    "    .filter(F.col(\"name\") == \"Moscow\")\n",
    "    .explain(True)\n",
    ")\n",
    "\n",
    "## по плану запроса видно, что Physical Plan (физический движок с вызовом конкретных методов)\n",
    "## сначала делает скан  коллекции а после применяется метод Filter для проверки того условия,\n",
    "## что мы указали в методах к DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2c69d7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+---------+----------+\n",
      "|continent|country|     name|population|\n",
      "+---------+-------+---------+----------+\n",
      "|   Europe| Russia|   Moscow| 100000000|\n",
      "|     null|  Spain|   Madrid|      null|\n",
      "|   Europe| France|    Paris| 205000000|\n",
      "|   Europe|Germany|   Berlin| 140000008|\n",
      "|   Europe|  Spain|Barselona|      null|\n",
      "|   Africa|  Egypt|    Cairo|  45000001|\n",
      "|   Africa|  Egypt|    Cairo|  45000001|\n",
      "+---------+-------+---------+----------+\n",
      "\n",
      "+---------+-------+---------+----------+\n",
      "|continent|country|     name|population|\n",
      "+---------+-------+---------+----------+\n",
      "|   Europe|Germany|   Berlin| 140000008|\n",
      "|     null|  Spain|   Madrid|      null|\n",
      "|   Africa|  Egypt|    Cairo|  45000001|\n",
      "|   Europe|  Spain|Barselona|      null|\n",
      "|   Europe| France|    Paris| 205000000|\n",
      "|   Europe| Russia|   Moscow| 100000000|\n",
      "+---------+-------+---------+----------+\n",
      "\n",
      "== Parsed Logical Plan ==\n",
      "Deduplicate [continent#6, country#7, name#8, population#9L]\n",
      "+- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "continent: string, country: string, name: string, population: bigint\n",
      "Deduplicate [continent#6, country#7, name#8, population#9L]\n",
      "+- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [continent#6, country#7, name#8, population#9L], [continent#6, country#7, name#8, population#9L]\n",
      "+- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[continent#6, country#7, name#8, population#9L], functions=[], output=[continent#6, country#7, name#8, population#9L])\n",
      "+- Exchange hashpartitioning(continent#6, country#7, name#8, population#9L, 200), true, [id=#341]\n",
      "   +- *(1) HashAggregate(keys=[continent#6, country#7, name#8, population#9L], functions=[], output=[continent#6, country#7, name#8, population#9L])\n",
      "      +- *(1) Scan ExistingRDD[continent#6,country#7,name#8,population#9L]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .show() ## в таком вызове в данных видим полные дубли по строкам, конкретно в данных по Африке\n",
    ")\n",
    "\n",
    "(\n",
    "    df\n",
    "    .dropDuplicates() ## метод выявления дублей и их удалние, если аргументов нет - дубли ищутся по всем строкам\n",
    "    .show()\n",
    ")\n",
    "\n",
    "(\n",
    "    df\n",
    "    .dropDuplicates() \n",
    "    .explain(True)\n",
    ")\n",
    "\n",
    "## по плану запроса видно, что Physical Plan (физический движок с вызовом конкретных методов)\n",
    "## сначала скан коллекции а после связка трех методов - HashAggregate, Exchange hashpartitioning и снова HashAggregate\n",
    "## посянение почему так метод реализуется на уровне движка лучше в записи семинара\n",
    "## я там явно проговариваю логику работы оптимизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ca737f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+---------+----------+\n",
      "|continent|country|     name|population|\n",
      "+---------+-------+---------+----------+\n",
      "|   Europe| Russia|   Moscow| 100000000|\n",
      "|     null|  Spain|   Madrid|      null|\n",
      "|   Europe| France|    Paris| 205000000|\n",
      "|   Europe|Germany|   Berlin| 140000008|\n",
      "|   Europe|  Spain|Barselona|      null|\n",
      "|   Africa|  Egypt|    Cairo|  45000001|\n",
      "|   Africa|  Egypt|    Cairo|  45000001|\n",
      "+---------+-------+---------+----------+\n",
      "\n",
      "+---------+-------+---------+----------+\n",
      "|continent|country|     name|population|\n",
      "+---------+-------+---------+----------+\n",
      "|     null|  Spain|   Madrid|      null|\n",
      "|   Africa|  Egypt|    Cairo|  45000001|\n",
      "|   Africa|  Egypt|    Cairo|  45000001|\n",
      "|   Europe| Russia|   Moscow| 100000000|\n",
      "|   Europe|Germany|   Berlin| 140000008|\n",
      "|   Europe| France|    Paris| 205000000|\n",
      "|   Europe|  Spain|Barselona|      null|\n",
      "+---------+-------+---------+----------+\n",
      "\n",
      "== Parsed Logical Plan ==\n",
      "'Sort ['continent ASC NULLS FIRST], true\n",
      "+- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "continent: string, country: string, name: string, population: bigint\n",
      "Sort [continent#6 ASC NULLS FIRST], true\n",
      "+- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [continent#6 ASC NULLS FIRST], true\n",
      "+- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) Sort [continent#6 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(continent#6 ASC NULLS FIRST, 200), true, [id=#375]\n",
      "   +- *(1) Scan ExistingRDD[continent#6,country#7,name#8,population#9L]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .show() \n",
    ")\n",
    "\n",
    "(\n",
    "    df\n",
    "    .orderBy(F.asc(\"continent\")) ## метод сортировки данных, обычно полезен для визуализации какой-то части данных в вашем выводе\n",
    "    .show()\n",
    ")\n",
    "\n",
    "(\n",
    "    df\n",
    "    .orderBy(F.asc(\"continent\"))\n",
    "    .explain(True)\n",
    ")\n",
    "\n",
    "## по плану запроса видно, что Physical Plan (физический движок с вызовом конкретных методов)\n",
    "## Важное замечание - тут вызывается Exchange rangepartitioning, который сильно хуже оптимизирован, чем Exchange hashpartitioning\n",
    "## Метод сортировки данных стоит использовать только для промежуточных вычислений, если в задаче обработки данных у вас\n",
    "## явно ничего нет про сортировку фрейма данных\n",
    "## подробнее про виды partitioning стоит прочитать в доке по ссылкам выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d762c01d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Join UsingJoin(Inner,Buffer(name))\n",
      ":- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "+- LogicalRDD [continent#308, country#309, name#310, population#311L], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "name: string, continent: string, country: string, population: bigint, continent: string, country: string, population: bigint\n",
      "Project [name#8, continent#6, country#7, population#9L, continent#308, country#309, population#311L]\n",
      "+- Join Inner, (name#8 = name#310)\n",
      "   :- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "   +- LogicalRDD [continent#308, country#309, name#310, population#311L], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [name#8, continent#6, country#7, population#9L, continent#308, country#309, population#311L]\n",
      "+- Join Inner, (name#8 = name#310)\n",
      "   :- Filter isnotnull(name#8)\n",
      "   :  +- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "   +- Filter isnotnull(name#310)\n",
      "      +- LogicalRDD [continent#308, country#309, name#310, population#311L], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(5) Project [name#8, continent#6, country#7, population#9L, continent#308, country#309, population#311L]\n",
      "+- *(5) SortMergeJoin [name#8], [name#310], Inner\n",
      "   :- *(2) Sort [name#8 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(name#8, 200), true, [id=#410]\n",
      "   :     +- *(1) Filter isnotnull(name#8)\n",
      "   :        +- *(1) Scan ExistingRDD[continent#6,country#7,name#8,population#9L]\n",
      "   +- *(4) Sort [name#310 ASC NULLS FIRST], false, 0\n",
      "      +- ReusedExchange [continent#308, country#309, name#310, population#311L], Exchange hashpartitioning(name#8, 200), true, [id=#410]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## джойны и их планы запросов\n",
    "(\n",
    "    df\n",
    "    .join(\n",
    "        df,\n",
    "        on=[\"name\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .explain(True)\n",
    ")\n",
    "\n",
    "## по плану запроса видно, что Physical Plan (физический движок с вызовом конкретных методов)\n",
    "## Видим выбор SortMergeJoin подхода в движке\n",
    "## и предварительные сортировки ключей \"Sort [name#8 ASC NULLS FIRST], false, 0\" чтобы раскидать их по нодам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "401f6e89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Join UsingJoin(Inner,Buffer(name))\n",
      ":- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "+- ResolvedHint (strategy=broadcast)\n",
      "   +- LogicalRDD [continent#319, country#320, name#321, population#322L], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "name: string, continent: string, country: string, population: bigint, continent: string, country: string, population: bigint\n",
      "Project [name#8, continent#6, country#7, population#9L, continent#319, country#320, population#322L]\n",
      "+- Join Inner, (name#8 = name#321)\n",
      "   :- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "   +- ResolvedHint (strategy=broadcast)\n",
      "      +- LogicalRDD [continent#319, country#320, name#321, population#322L], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [name#8, continent#6, country#7, population#9L, continent#319, country#320, population#322L]\n",
      "+- Join Inner, (name#8 = name#321), rightHint=(strategy=broadcast)\n",
      "   :- Filter isnotnull(name#8)\n",
      "   :  +- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "   +- Filter isnotnull(name#321)\n",
      "      +- LogicalRDD [continent#319, country#320, name#321, population#322L], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) Project [name#8, continent#6, country#7, population#9L, continent#319, country#320, population#322L]\n",
      "+- *(2) BroadcastHashJoin [name#8], [name#321], Inner, BuildRight\n",
      "   :- *(2) Filter isnotnull(name#8)\n",
      "   :  +- *(2) Scan ExistingRDD[continent#6,country#7,name#8,population#9L]\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[2, string, false])), [id=#471]\n",
      "      +- *(1) Filter isnotnull(name#321)\n",
      "         +- *(1) Scan ExistingRDD[continent#319,country#320,name#321,population#322L]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## джойны и их планы запросов\n",
    "(\n",
    "    df\n",
    "    .join(\n",
    "        F.broadcast(df),\n",
    "        on=[\"name\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .explain(True)\n",
    ")\n",
    "\n",
    "## по плану запроса видно, что Physical Plan (физический движок с вызовом конкретных методов)\n",
    "## Видим выбор BroadcastHashJoin, потому что к одному из фреймов явно применили Broadcast метод\n",
    "## про этот метод есть пояснение в лекции\n",
    "## также важно: видно что здесь нет этапа сортировки ключей, даже на втором фрейме данных\n",
    "## отсуствие этого этапа рассчета для джойна и дает нам оптимизацию по времени его работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a7133436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Join Inner, NOT (name#8 = name#332)\n",
      ":- SubqueryAlias a\n",
      ":  +- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "+- ResolvedHint (strategy=broadcast)\n",
      "   +- SubqueryAlias b\n",
      "      +- LogicalRDD [continent#330, country#331, name#332, population#333L], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "continent: string, country: string, name: string, population: bigint, continent: string, country: string, name: string, population: bigint\n",
      "Join Inner, NOT (name#8 = name#332)\n",
      ":- SubqueryAlias a\n",
      ":  +- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "+- ResolvedHint (strategy=broadcast)\n",
      "   +- SubqueryAlias b\n",
      "      +- LogicalRDD [continent#330, country#331, name#332, population#333L], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Join Inner, NOT (name#8 = name#332), rightHint=(strategy=broadcast)\n",
      ":- Filter isnotnull(name#8)\n",
      ":  +- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "+- Filter isnotnull(name#332)\n",
      "   +- LogicalRDD [continent#330, country#331, name#332, population#333L], false\n",
      "\n",
      "== Physical Plan ==\n",
      "BroadcastNestedLoopJoin BuildRight, Inner, NOT (name#8 = name#332)\n",
      ":- *(1) Filter isnotnull(name#8)\n",
      ":  +- *(1) Scan ExistingRDD[continent#6,country#7,name#8,population#9L]\n",
      "+- BroadcastExchange IdentityBroadcastMode, [id=#499]\n",
      "   +- *(2) Filter isnotnull(name#332)\n",
      "      +- *(2) Scan ExistingRDD[continent#330,country#331,name#332,population#333L]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## джойны и их планы запросов\n",
    "(\n",
    "    df.alias(\"a\")\n",
    "    .join(\n",
    "        F.broadcast(df.alias(\"b\")),\n",
    "        on=F.col(\"a.name\") != F.col(\"b.name\"),\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .explain(True)\n",
    ")\n",
    "\n",
    "## по плану запроса видно, что Physical Plan (физический движок с вызовом конкретных методов)\n",
    "## Видим выбор BroadcastNestedLoopJoin по причине того,\n",
    "## что условие джйона не вписывается в проверку ключей на равенство + применем Broadcast к одному из фреймов данных\n",
    "## Сортировки ключей тут также нет\n",
    "## Но join данных по частям на каждом воркере будет выполняться через вложенный цикл, из-за сложности условия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7c35452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Join Inner, NOT (name#8 = name#360)\n",
      ":- SubqueryAlias a\n",
      ":  +- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "+- SubqueryAlias b\n",
      "   +- LogicalRDD [continent#358, country#359, name#360, population#361L], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "continent: string, country: string, name: string, population: bigint, continent: string, country: string, name: string, population: bigint\n",
      "Join Inner, NOT (name#8 = name#360)\n",
      ":- SubqueryAlias a\n",
      ":  +- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "+- SubqueryAlias b\n",
      "   +- LogicalRDD [continent#358, country#359, name#360, population#361L], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Join Inner, NOT (name#8 = name#360)\n",
      ":- Filter isnotnull(name#8)\n",
      ":  +- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "+- Filter isnotnull(name#360)\n",
      "   +- LogicalRDD [continent#358, country#359, name#360, population#361L], false\n",
      "\n",
      "== Physical Plan ==\n",
      "CartesianProduct NOT (name#8 = name#360)\n",
      ":- *(1) Filter isnotnull(name#8)\n",
      ":  +- *(1) Scan ExistingRDD[continent#6,country#7,name#8,population#9L]\n",
      "+- *(2) Filter isnotnull(name#360)\n",
      "   +- *(2) Scan ExistingRDD[continent#358,country#359,name#360,population#361L]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## джойны и их планы запросов\n",
    "\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\") ## для след примера выключим автоматический Broadcast\n",
    "## небольших фреймов данных\n",
    "\n",
    "(\n",
    "    df.alias(\"a\")\n",
    "    .join(\n",
    "        df.alias(\"b\"),\n",
    "        on=F.col(\"a.name\") != F.col(\"b.name\"),\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .explain(True)\n",
    ")\n",
    "\n",
    "## по плану запроса видно, что Physical Plan (физический движок с вызовом конкретных методов)\n",
    "## Видим выбор CartesianProduct, самый \"долгий\" из физических подходов по вычислению работы джойна\n",
    "## В силу сложности условия джойна + невозможности применить Broadcast (мы его буквально отключили)\n",
    "## был выбран CartesianProduct метод\n",
    "## оптимизаций тут нет, данные распределяются на все возможные паросочетания ключей\n",
    "## раскидываются на ноды по хэшу и после проверяются по условию на правильно объединения данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17fca3e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Filter ('name_exp = s)\n",
      "+- Project [continent#6, country#7, name#8, population#9L, name_sep#386, name_exp#393]\n",
      "   +- Generate explode(name_sep#386), false, [name_exp#393]\n",
      "      +- Project [continent#6, country#7, name#8, population#9L, split(name#8, , -1) AS name_sep#386]\n",
      "         +- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "continent: string, country: string, name: string, population: bigint, name_sep: array<string>, name_exp: string\n",
      "Filter (name_exp#393 = s)\n",
      "+- Project [continent#6, country#7, name#8, population#9L, name_sep#386, name_exp#393]\n",
      "   +- Generate explode(name_sep#386), false, [name_exp#393]\n",
      "      +- Project [continent#6, country#7, name#8, population#9L, split(name#8, , -1) AS name_sep#386]\n",
      "         +- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Filter (isnotnull(name_exp#393) AND (name_exp#393 = s))\n",
      "+- Generate explode(name_sep#386), false, [name_exp#393]\n",
      "   +- Project [continent#6, country#7, name#8, population#9L, split(name#8, , -1) AS name_sep#386]\n",
      "      +- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) Filter (isnotnull(name_exp#393) AND (name_exp#393 = s))\n",
      "+- Generate explode(name_sep#386), [continent#6, country#7, name#8, population#9L, name_sep#386], false, [name_exp#393]\n",
      "   +- *(1) Project [continent#6, country#7, name#8, population#9L, split(name#8, , -1) AS name_sep#386]\n",
      "      +- *(1) Scan ExistingRDD[continent#6,country#7,name#8,population#9L]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ниже план запроса методов split и explode\n",
    "## которые превращают строковую колонку в СПИСОК символов\n",
    "## а после список символов мы раскидываем на уникальные значения для каждой строки, тем самым\n",
    "## на каждый эл-т из списка создаем новую строку\n",
    "\n",
    "(\n",
    "    df\n",
    "    .withColumn(\"name_sep\", F.split(\"name\", \"\"))\n",
    "    .withColumn(\"name_exp\", F.explode(\"name_sep\"))\n",
    "    .filter(F.col(\"name_exp\") == \"s\")\n",
    "    .explain(True)\n",
    ")\n",
    "\n",
    "## Логику отработки этого метода можно увидеть на, Physical Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f46e6a7",
   "metadata": {},
   "source": [
    "## Сравнение реализаций задачи над RDD и DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40f5b580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('france', 1), ('egypt', 2), ('russia', 1), ('spain', 2), ('germany', 1)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## пример задачи через RDD на подсчет числа упоминаний стран в данных\n",
    "\n",
    "\n",
    "rdd \\\n",
    "    .map(lambda x: x['country'].lower()) \\\n",
    "    .map( lambda x: (x, 1)) \\\n",
    "    .reduceByKey( lambda x,y: x + y) \\\n",
    "    .collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d48cd208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Aggregate ['country], [unresolvedalias('country, None), count(1) AS count(1)#405L]\n",
      "+- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "country: string, count(1): bigint\n",
      "Aggregate [country#7], [country#7, count(1) AS count(1)#405L]\n",
      "+- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [country#7], [country#7, count(1) AS count(1)#405L]\n",
      "+- Project [country#7]\n",
      "   +- LogicalRDD [continent#6, country#7, name#8, population#9L], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[country#7], functions=[count(1)], output=[country#7, count(1)#405L])\n",
      "+- Exchange hashpartitioning(country#7, 200), true, [id=#560]\n",
      "   +- *(1) HashAggregate(keys=[country#7], functions=[partial_count(1)], output=[country#7, count#409L])\n",
      "      +- *(1) Project [country#7]\n",
      "         +- *(1) Scan ExistingRDD[continent#6,country#7,name#8,population#9L]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## она же через DataFrame API\n",
    "(\n",
    "    df\n",
    "    .groupBy(\"country\")\n",
    "    .agg(F.count(\"*\"))\n",
    "    .explain(True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3322f261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
